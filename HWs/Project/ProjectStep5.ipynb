{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b9f02c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Age  RestingBP  Cholesterol  FastingBS     MaxHR  Oldpeak  \\\n",
      "0   -1.334331   0.548422     0.984547          0  1.290461      0.0   \n",
      "1   -0.390470   1.845686    -1.182352          0  0.633456      1.0   \n",
      "2   -1.648952  -0.100209     0.865268          0 -1.748185      0.0   \n",
      "3   -0.495344   0.418696    -0.506439          0 -1.337557      1.5   \n",
      "4    0.133897   1.197054    -0.884155          0 -0.762678      0.0   \n",
      "..        ...        ...          ...        ...       ...      ...   \n",
      "913 -0.809964  -1.397473     0.487552          0 -0.352050      1.2   \n",
      "914  1.602125   0.807875    -0.923915          1  0.017515      3.4   \n",
      "915  0.448517  -0.100209    -2.156463          0 -1.050118      1.2   \n",
      "916  0.448517  -0.100209    -0.069083          0  1.372586      0.0   \n",
      "917 -1.544078   0.418696    -1.281751          0  1.331524      0.0   \n",
      "\n",
      "     HeartDisease  Sex_F  Sex_M  ChestPainType_ASY  ...  ChestPainType_NAP  \\\n",
      "0               0      0      1                  0  ...                  0   \n",
      "1               1      1      0                  0  ...                  1   \n",
      "2               0      0      1                  0  ...                  0   \n",
      "3               1      1      0                  1  ...                  0   \n",
      "4               0      0      1                  0  ...                  1   \n",
      "..            ...    ...    ...                ...  ...                ...   \n",
      "913             1      0      1                  0  ...                  0   \n",
      "914             1      0      1                  1  ...                  0   \n",
      "915             1      0      1                  1  ...                  0   \n",
      "916             1      1      0                  0  ...                  0   \n",
      "917             0      0      1                  0  ...                  1   \n",
      "\n",
      "     ChestPainType_TA  RestingECG_LVH  RestingECG_Normal  RestingECG_ST  \\\n",
      "0                   0               0                  1              0   \n",
      "1                   0               0                  1              0   \n",
      "2                   0               0                  0              1   \n",
      "3                   0               0                  1              0   \n",
      "4                   0               0                  1              0   \n",
      "..                ...             ...                ...            ...   \n",
      "913                 1               0                  1              0   \n",
      "914                 0               0                  1              0   \n",
      "915                 0               0                  1              0   \n",
      "916                 0               1                  0              0   \n",
      "917                 0               0                  1              0   \n",
      "\n",
      "     ExerciseAngina_N  ExerciseAngina_Y  ST_Slope_Down  ST_Slope_Flat  \\\n",
      "0                   1                 0              0              0   \n",
      "1                   1                 0              0              1   \n",
      "2                   1                 0              0              0   \n",
      "3                   0                 1              0              1   \n",
      "4                   1                 0              0              0   \n",
      "..                ...               ...            ...            ...   \n",
      "913                 1                 0              0              1   \n",
      "914                 1                 0              0              1   \n",
      "915                 0                 1              0              1   \n",
      "916                 1                 0              0              1   \n",
      "917                 1                 0              0              0   \n",
      "\n",
      "     ST_Slope_Up  \n",
      "0              1  \n",
      "1              0  \n",
      "2              1  \n",
      "3              0  \n",
      "4              1  \n",
      "..           ...  \n",
      "913            0  \n",
      "914            0  \n",
      "915            0  \n",
      "916            0  \n",
      "917            1  \n",
      "\n",
      "[701 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Step 1: Data pre-processing phase\n",
    "def preprocess_data(data):\n",
    "    \n",
    "    # Categorical to Numeric\n",
    "    data = pd.get_dummies(data, columns=['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope'], dtype='int')\n",
    "    \n",
    "    columns_to_process = ['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']\n",
    "    \n",
    "    for column in columns_to_process:\n",
    "        Q1 = data[column].quantile(0.25)\n",
    "        Q3 = data[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # Apply outlier removal only to the selected column\n",
    "        data = data.loc[(data[column] >= (Q1 - 1.5 * IQR)) & (data[column] <= (Q3 + 1.5 * IQR))]\n",
    "    return data\n",
    "\n",
    "def normalize_data(org_df,col):\n",
    "    col_array = np.array(org_df[col]).reshape(-1, 1)\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    scaler.fit(col_array)\n",
    "    org_df[col] = scaler.transform(col_array)\n",
    "    return org_df\n",
    "\n",
    "# Load data\n",
    "file_path = '/Users/zhangxijing/MasterNEU/INFO6105DataScienceEngineeringMethodsandTools/Dataset/Heart_Failure.csv'  # Update this path to your new dataset\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "data = preprocess_data(data)\n",
    "\n",
    "data = normalize_data(data,'Age')\n",
    "data = normalize_data(data,'RestingBP')\n",
    "data = normalize_data(data,'Cholesterol')\n",
    "data = normalize_data(data,'MaxHR')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7e08c049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data after PCA:\n",
      "        PC1       PC2       PC3  outcome\n",
      "0  2.558396 -1.349264 -1.341968        1\n",
      "1 -1.551547 -1.506064  0.450147        0\n",
      "2  3.624999 -1.041258  0.422356        1\n",
      "3  1.934112  0.358389  0.422603        1\n",
      "4  2.672908  3.006461 -1.672042        1\n",
      "Testing data after PCA:\n",
      "        PC1       PC2       PC3  outcome\n",
      "0  2.920527 -0.964144 -1.484184        1\n",
      "1  2.742748 -1.210056 -1.164814        1\n",
      "2  1.789398 -1.858782 -1.518943        1\n",
      "3 -1.804309  0.867948  1.881906        0\n",
      "4  0.831860 -1.225375 -0.314270        1\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Feature Extraction\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.drop('HeartDisease', axis=1)  # Exclude the outcome column\n",
    "y = data['HeartDisease']\n",
    "\n",
    "# Split data into training and test sets (considering 20% for test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Standardize the features (important for PCA)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply PCA to create 3 new components from existing features\n",
    "pca = PCA(n_components=3)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Transfer training and test data to the new dimensions (PCs)\n",
    "X_train_transformed = pd.DataFrame(X_train_pca, columns=['PC1', 'PC2', 'PC3'])\n",
    "X_test_transformed = pd.DataFrame(X_test_pca, columns=['PC1', 'PC2', 'PC3'])\n",
    "\n",
    "# Append the outcome column back to the transformed data\n",
    "X_train_transformed['outcome'] = y_train.reset_index(drop=True)\n",
    "X_test_transformed['outcome'] = y_test.reset_index(drop=True)\n",
    "\n",
    "print(\"Training data after PCA:\")\n",
    "print(X_train_transformed.head())\n",
    "\n",
    "print(\"Testing data after PCA:\")\n",
    "print(X_test_transformed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cc6a1b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: Training base classifiers and meta learner using 5-fold cross validation...\n",
      "Training Naive Bayes...\n",
      "Training Neural Network...\n",
      "Training KNN...\n",
      "Training meta learner (Decision Tree) on meta features...\n",
      "Step 4: Finding best hyperparameters using GridSearchCV...\n",
      "Step 4: Evaluating model on test data...\n",
      "Generating predictions using Naive Bayes on test data...\n",
      "Generating predictions using Neural Network on test data...\n",
      "Generating predictions using KNN on test data...\n",
      "Accuracy of the Super Learner on Test Data: 0.8794\n",
      "Total Calculation Time: 15.26 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Step 4: Define base classifiers and meta learner\n",
    "base_classifiers = {\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Neural Network': MLPClassifier(max_iter=1000),  # You can adjust max_iter as needed\n",
    "    'KNN': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "meta_learner = DecisionTreeClassifier()\n",
    "\n",
    "print(\"Step 4: Training base classifiers and meta learner using 5-fold cross validation...\")\n",
    "\n",
    "start_time = time.time()  # Record start time\n",
    "\n",
    "# Step 4: Train base classifiers and meta learner using 5-fold cross validation\n",
    "meta_features_train = []\n",
    "for name, clf in base_classifiers.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    \n",
    "    # Fit the base classifier on the entire training data\n",
    "    clf.fit(X_train_transformed.drop('outcome', axis=1), X_train_transformed['outcome'])\n",
    "    \n",
    "    # Generate predictions from the base classifier using cross-validation\n",
    "    predictions = cross_val_predict(clf, X_train_transformed.drop('outcome', axis=1), X_train_transformed['outcome'], cv=5)\n",
    "    meta_features_train.append(predictions)\n",
    "\n",
    "# Stack predictions horizontally to form meta features\n",
    "meta_features_train = np.array(meta_features_train).T\n",
    "\n",
    "print(\"Training meta learner (Decision Tree) on meta features...\")\n",
    "# Train the meta learner (decision tree) on the meta features\n",
    "meta_learner.fit(meta_features_train, X_train_transformed['outcome'])\n",
    "\n",
    "print(\"Step 4: Finding best hyperparameters using GridSearchCV...\")\n",
    "\n",
    "# Step 4: Find best hyperparameters using GridSearchCV for Neural Network\n",
    "param_grid_nn = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "    'alpha': [0.0001, 0.001, 0.01]\n",
    "}\n",
    "\n",
    "grid_search_nn = GridSearchCV(base_classifiers['Neural Network'], param_grid=param_grid_nn, cv=5)\n",
    "grid_search_nn.fit(X_train_transformed.drop('outcome', axis=1), X_train_transformed['outcome'])\n",
    "\n",
    "best_nn_classifier = grid_search_nn.best_estimator_\n",
    "\n",
    "print(\"Step 4: Evaluating model on test data...\")\n",
    "\n",
    "# Step 4: Evaluate model on test data\n",
    "meta_features_test = []\n",
    "for name, clf in base_classifiers.items():\n",
    "    print(f\"Generating predictions using {name} on test data...\")\n",
    "    \n",
    "    # Generate predictions from the base classifier on test data\n",
    "    predictions_test = clf.predict(X_test_transformed.drop('outcome', axis=1))\n",
    "    meta_features_test.append(predictions_test)\n",
    "\n",
    "# Stack predictions horizontally for test data\n",
    "meta_features_test = np.array(meta_features_test).T\n",
    "\n",
    "# Use the trained meta learner to make predictions on test data\n",
    "final_predictions = meta_learner.predict(meta_features_test)\n",
    "\n",
    "# Calculate accuracy of the final model on test data\n",
    "accuracy = accuracy_score(X_test_transformed['outcome'], final_predictions)\n",
    "print(f\"Accuracy of the Super Learner on Test Data: {accuracy:.4f}\")\n",
    "\n",
    "end_time = time.time()  # Record end time\n",
    "calculation_time = end_time - start_time\n",
    "print(f\"Total Calculation Time: {calculation_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd20b78d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
